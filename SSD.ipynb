{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " SSD",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Divyanshu-Singh-Chauhan/Emojify-model/blob/master/SSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JG-1Zy0ZhJRa",
        "colab_type": "text"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np3SZt2Fd4Ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTM1HIcChgpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O images.zip https://files.slack.com/files-pri/TJRDXSH3L-FKMNSAEFK/download/images.zip?pub_secret=37264d575e"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNr532sdhzSC",
        "colab_type": "text"
      },
      "source": [
        "#Model Definitions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu32VOsDh30h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision.data import ObjectCategoryList, ObjectItemList, imagenet_stats\n",
        "from fastai.vision.image import ImageBBox\n",
        "import torch\n",
        "\n",
        "\n",
        "def nms(boxes, scores, overlap=0.5, top_k=100):\n",
        "    keep = scores.new(scores.size(0)).zero_().long()\n",
        "    if boxes.numel() == 0: return keep\n",
        "    x1 = boxes[:, 0]\n",
        "    y1 = boxes[:, 1]\n",
        "    x2 = boxes[:, 2]\n",
        "    y2 = boxes[:, 3]\n",
        "    area = torch.mul(x2 - x1, y2 - y1)\n",
        "    v, idx = scores.sort(0)  # sort in ascending order\n",
        "    idx = idx[-top_k:]  # indices of the top-k largest vals\n",
        "    xx1 = boxes.new()\n",
        "    yy1 = boxes.new()\n",
        "    xx2 = boxes.new()\n",
        "    yy2 = boxes.new()\n",
        "    w = boxes.new()\n",
        "    h = boxes.new()\n",
        "\n",
        "    count = 0\n",
        "    while idx.numel() > 0:\n",
        "        i = idx[-1]  # index of current largest val\n",
        "        keep[count] = i\n",
        "        count += 1\n",
        "        if idx.size(0) == 1: break\n",
        "        idx = idx[:-1]  # remove kept element from view\n",
        "        # load bboxes of next highest vals\n",
        "        torch.index_select(x1, 0, idx, out=xx1)\n",
        "        torch.index_select(y1, 0, idx, out=yy1)\n",
        "        torch.index_select(x2, 0, idx, out=xx2)\n",
        "        torch.index_select(y2, 0, idx, out=yy2)\n",
        "        # store element-wise max with next highest score\n",
        "        xx1 = torch.clamp(xx1, min=x1[i])\n",
        "        yy1 = torch.clamp(yy1, min=y1[i])\n",
        "        xx2 = torch.clamp(xx2, max=x2[i])\n",
        "        yy2 = torch.clamp(yy2, max=y2[i])\n",
        "        w.resize_as_(xx2)\n",
        "        h.resize_as_(yy2)\n",
        "        w = xx2 - xx1\n",
        "        h = yy2 - yy1\n",
        "        # check sizes of xx1 and xx2.. after each iteration\n",
        "        w = torch.clamp(w, min=0.0)\n",
        "        h = torch.clamp(h, min=0.0)\n",
        "        inter = w*h\n",
        "        # IoU = i / (area(a) + area(b) - i)\n",
        "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n",
        "        union = (rem_areas - inter) + area[i]\n",
        "        IoU = inter/union  # store result in iou\n",
        "        # keep only elements with an IoU <= overlap\n",
        "        idx = idx[IoU.le(overlap)]\n",
        "    return keep, count\n",
        "\n",
        "\n",
        "class SSDObjectCategoryList(ObjectCategoryList):\n",
        "    \"`ItemList` for labelled bounding boxes detected using SSD.\"\n",
        "    def analyze_pred(self, pred, thresh=0.5, nms_overlap=0.1, ssd=None):\n",
        "        # def analyze_pred(pred, anchors, grid_sizes, thresh=0.5, nms_overlap=0.1, ssd=None):\n",
        "        b_clas, b_bb = pred\n",
        "        a_ic = ssd._actn_to_bb(b_bb, ssd._anchors.cpu(), ssd._grid_sizes.cpu())\n",
        "        conf_scores, clas_ids = b_clas[:, 1:].max(1)\n",
        "        conf_scores = b_clas.t().sigmoid()\n",
        "\n",
        "        out1, bbox_list, class_list = [], [], []\n",
        "\n",
        "        for cl in range(1, len(conf_scores)):\n",
        "            c_mask = conf_scores[cl] > thresh\n",
        "            if c_mask.sum() == 0: \n",
        "                continue\n",
        "            scores = conf_scores[cl][c_mask]\n",
        "            l_mask = c_mask.unsqueeze(1)\n",
        "            l_mask = l_mask.expand_as(a_ic)\n",
        "            boxes = a_ic[l_mask].view(-1, 4) # boxes are now in range[ 0, 1]\n",
        "            boxes = (boxes-0.5) * 2.0        # putting boxes in range[-1, 1]\n",
        "            ids, count = nms(boxes.data, scores, nms_overlap, 50) # FIX- NMS overlap hardcoded\n",
        "            ids = ids[:count]\n",
        "            out1.append(scores[ids])\n",
        "            bbox_list.append(boxes.data[ids])\n",
        "            class_list.append(torch.tensor([cl]*count))\n",
        "\n",
        "        if len(bbox_list) == 0:\n",
        "            return None #torch.Tensor(size=(0,4)), torch.Tensor()\n",
        "\n",
        "        return torch.cat(bbox_list, dim=0), torch.cat(class_list, dim=0) # torch.cat(out1, dim=0), \n",
        "\n",
        "    \n",
        "    def reconstruct(self, t, x):\n",
        "        if t is None: return None\n",
        "        bboxes, labels = t\n",
        "        if len((labels - self.pad_idx).nonzero()) == 0: return\n",
        "        i = (labels - self.pad_idx).nonzero().min()\n",
        "        bboxes,labels = bboxes[i:],labels[i:]\n",
        "        return ImageBBox.create(*x.size, bboxes, labels=labels, classes=self.classes, scale=False)\n",
        "\n",
        "    \n",
        "class SSDObjectItemList(ObjectItemList):\n",
        "    \"`ItemList` suitable for object detection.\"\n",
        "    _label_cls,_square_show_res = SSDObjectCategoryList,False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSIxyq1JiCT0",
        "colab_type": "text"
      },
      "source": [
        "###utility functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqQFsQY0iIfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def conv_params(in_size, out_size):\n",
        "    filters = [3,2,5,4]\n",
        "    strides = [1,2,3] # max_stride = 3\n",
        "    pads = [0,1,2,3] # max pad\n",
        "    \n",
        "    if out_size == 1:\n",
        "        return 1, 0, in_size\n",
        "    \n",
        "    for filter_size in filters:\n",
        "        for pad in pads:\n",
        "            for stride in strides:\n",
        "                if ((out_size - 1) * stride == (in_size - filter_size) + 2 * pad):\n",
        "                    return stride, pad, filter_size\n",
        "    return None, None, None\n",
        "\n",
        "class StdConv(nn.Module):\n",
        "    def __init__(self, nin, nout, filter_size=3, stride=2, padding=1, drop=0.1):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(nin, nout, filter_size, stride=stride, padding=padding)\n",
        "        self.bn = nn.BatchNorm2d(nout)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        \n",
        "    def forward(self, x): \n",
        "        return self.drop(self.bn(F.relu(self.conv(x))))\n",
        "        \n",
        "def flatten_conv(x,k):\n",
        "    bs,nf,gx,gy = x.size()\n",
        "    x = x.permute(0,2,3,1).contiguous()\n",
        "    return x.view(bs,-1,nf//k)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, k, nin, num_classes, bias):\n",
        "        super().__init__()\n",
        "        self.k = k\n",
        "        self.oconv1 = nn.Conv2d(nin, (num_classes)*k, 3, padding=1)\n",
        "        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)\n",
        "        self.oconv1.bias.data.zero_().add_(bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return [flatten_conv(self.oconv1(x), self.k),\n",
        "                flatten_conv(self.oconv2(x), self.k)]\n",
        "    \n",
        "class SSDHead(nn.Module):\n",
        "    def __init__(self, grids, anchors_per_cell, num_classes, drop=0.3, bias=-4.):\n",
        "        super().__init__()\n",
        "        self.drop = nn.Dropout(drop)\n",
        "        \n",
        "        self.sconvs = nn.ModuleList([])\n",
        "        self.oconvs = nn.ModuleList([])\n",
        "        \n",
        "        self.anc_grids = grids\n",
        "        \n",
        "        self._k = anchors_per_cell\n",
        "\n",
        "        \n",
        "        self.sconvs.append(StdConv(512, 256, stride=1, drop=drop))\n",
        "        \n",
        "        \n",
        "        for i in range(len(grids)):\n",
        "            \n",
        "            if i == 0:\n",
        "                stride, pad, filter_size = conv_params(7, grids[i]) # get '7' by base model\n",
        "            else:\n",
        "                stride, pad, filter_size = conv_params(grids[i-1], grids[i])\n",
        "            \n",
        "            if stride is None:\n",
        "                print(grids[i-1], ' --> ', grids[i])\n",
        "                raise Exception('cannot create model for specified grids')\n",
        "                \n",
        "            self.sconvs.append(StdConv(256, 256, filter_size, stride=stride, padding=pad, drop=drop))\n",
        "            self.oconvs.append(OutConv(self._k, 256, num_classes=num_classes, bias=bias))\n",
        "                \n",
        "    def forward(self, x):\n",
        "        x = self.drop(F.relu(x))\n",
        "        x = self.sconvs[0](x)\n",
        "        out_classes = []\n",
        "        out_bboxes = []\n",
        "        for sconv, oconv in zip(self.sconvs[1:], self.oconvs):\n",
        "            x = sconv(x)\n",
        "            out_class, out_bbox = oconv(x)\n",
        "            out_classes.append(out_class)\n",
        "            out_bboxes.append(out_bbox)\n",
        "            \n",
        "        return [torch.cat(out_classes, dim=1),\n",
        "                torch.cat(out_bboxes, dim=1)]\n",
        "\n",
        "def one_hot_embedding(labels, num_classes):\n",
        "    return torch.eye(num_classes)[labels.data.cpu()]\n",
        "\n",
        "class BCE_Loss(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, pred, targ):\n",
        "        t = one_hot_embedding(targ, self.num_classes)\n",
        "        t = torch.Tensor(t[:,1:].contiguous()).cuda()\n",
        "        x = pred[:,1:]\n",
        "        w = self.get_weight(x,t)\n",
        "        return F.binary_cross_entropy_with_logits(x, t, w, size_average=False)/(self.num_classes-1)\n",
        "    \n",
        "    def get_weight(self,x,t): return None\n",
        "\n",
        "class FocalLoss(BCE_Loss):\n",
        "    def get_weight(self,x,t):\n",
        "        alpha,gamma = 0.25,1\n",
        "        p = x.sigmoid()\n",
        "        pt = p*t + (1-p)*(1-t)\n",
        "        w = alpha*t + (1-alpha)*(1-t)\n",
        "        w = w * (1-pt).pow(gamma)\n",
        "        return w.detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41yF2kbYiPNk",
        "colab_type": "text"
      },
      "source": [
        "###SIngle Shot Detector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gw6_iEiTph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from fastai.vision.learner import create_cnn\n",
        "from torchvision.models import resnet34\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "class _EmptyData():\n",
        "    def __init__(self, path, c, loss_func: None):\n",
        "        self.path = path\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
        "        self.c = c\n",
        "        self.loss_func = loss_func\n",
        "\n",
        "class SingleShotDetector(object):\n",
        "    \n",
        "    def __init__(self, data, grids=[4, 2, 1], zooms=[0.7, 1., 1.3], ratios=[[1., 1.], [1., 0.5], [0.5, 1.]], \n",
        "                 backbone=None, drop=0.3, bias=-4., focal_loss=False, pretrained_path=None):\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self._device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
        "\n",
        "\n",
        "        if backbone is None:\n",
        "            backbone = resnet34\n",
        "            \n",
        "        self._create_anchors(grids, zooms, ratios)\n",
        "        \n",
        "        ssd_head = SSDHead(grids, self._anchors_per_cell, data.c, drop=drop, bias=bias)\n",
        "\n",
        "        self._data = data\n",
        "        self.learn = create_cnn(data=data, base_arch=backbone, custom_head=ssd_head)\n",
        "        self.learn.model = self.learn.model.to(self._device)\n",
        "\n",
        "        if pretrained_path is not None:\n",
        "            self.load(pretrained_path)\n",
        "        \n",
        "        if focal_loss:\n",
        "            self._loss_f = FocalLoss(data.c)\n",
        "        else:\n",
        "            self._loss_f = BCE_Loss(data.c)\n",
        "            \n",
        "        self.learn.loss_func = self._ssd_loss\n",
        "\n",
        "    @classmethod\n",
        "    def from_emd(cls, data, emd_path):\n",
        "        emd = json.load(open(emd_path))\n",
        "        class_mapping = {i['Value'] : i['Name'] for i in emd['Classes']}\n",
        "        if data is None:\n",
        "            empty_data = _EmptyData(path='str', loss_func=None, c=len(class_mapping) + 1)\n",
        "            return cls(empty_data, emd['Grids'], emd['Zooms'], emd['Ratios'], pretrained_path=emd['ModelFile'])\n",
        "        else:\n",
        "            return cls(data, emd['Grids'], emd['Zooms'], emd['Ratios'], pretrained_path=emd['ModelFile'])\n",
        "\n",
        "    \n",
        "    def lr_find(self):\n",
        "        from IPython.display import clear_output\n",
        "        self.learn.lr_find()\n",
        "        clear_output()\n",
        "        self.learn.recorder.plot()\n",
        "        \n",
        "    def fit(self, epochs=10, lr=slice(1e-4,3e-3)):\n",
        "        self.learn.fit(epochs, lr)\n",
        "\n",
        "    def unfreeze():\n",
        "        self.learn.unfreeze()\n",
        "        \n",
        "    def _create_anchors(self, anc_grids, anc_zooms, anc_ratios):\n",
        "        \n",
        "        self.grids = anc_grids\n",
        "        self.zooms = anc_zooms\n",
        "        self.ratios =  anc_ratios\n",
        "\n",
        "        anchor_scales = [(anz*i, anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
        "        \n",
        "        self._anchors_per_cell = len(anchor_scales)\n",
        "        \n",
        "        anc_offsets = [1/(o*2) for o in anc_grids]\n",
        "\n",
        "        anc_x = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
        "                                for ao,ag in zip(anc_offsets,anc_grids)])\n",
        "        anc_y = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
        "                                for ao,ag in zip(anc_offsets,anc_grids)])\n",
        "        anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), self._anchors_per_cell, axis=0)\n",
        "\n",
        "        anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
        "                       for ag in anc_grids])\n",
        "        \n",
        "        self._grid_sizes = torch.Tensor(np.concatenate([np.array([ 1/ag  for i in range(ag*ag) for o,p in anchor_scales])\n",
        "                       for ag in anc_grids])).unsqueeze(1).to(self._device)\n",
        "        \n",
        "        self._anchors = torch.Tensor(np.concatenate([anc_ctrs, anc_sizes], axis=1)).float().to(self._device)\n",
        "        \n",
        "        self._anchor_cnr = self._hw2corners(self._anchors[:,:2], self._anchors[:,2:])\n",
        "        \n",
        "    def _hw2corners(self, ctr, hw): \n",
        "        return torch.cat([ctr-hw/2, ctr+hw/2], dim=1)\n",
        "\n",
        "    def _get_y(self, bbox, clas):\n",
        "        bbox = bbox.view(-1,4) #/sz\n",
        "        bb_keep = ((bbox[:,2]-bbox[:,0])>0).nonzero()[:,0]\n",
        "        return bbox[bb_keep],clas[bb_keep]\n",
        "\n",
        "    def _actn_to_bb(self, actn, anchors, grid_sizes):\n",
        "        actn_bbs = torch.tanh(actn)\n",
        "        actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]\n",
        "        actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n",
        "        return self._hw2corners(actn_centers, actn_hw)\n",
        "\n",
        "    def _map_to_ground_truth(self, overlaps, print_it=False):\n",
        "        prior_overlap, prior_idx = overlaps.max(1)\n",
        "        if print_it: print(prior_overlap)\n",
        "        gt_overlap, gt_idx = overlaps.max(0)\n",
        "        gt_overlap[prior_idx] = 1.99\n",
        "        for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
        "        return gt_overlap, gt_idx\n",
        "        \n",
        "        \n",
        "    def _ssd_1_loss(self, b_c, b_bb, bbox, clas, print_it=False):\n",
        "        bbox,clas = self._get_y(bbox,clas)\n",
        "        bbox = self._normalize_bbox(bbox)\n",
        "\n",
        "        a_ic = self._actn_to_bb(b_bb, self._anchors, self._grid_sizes)\n",
        "        overlaps = self._jaccard(bbox.data, self._anchor_cnr.data)\n",
        "        try:\n",
        "            gt_overlap,gt_idx = self._map_to_ground_truth(overlaps,print_it)\n",
        "        except Exception as e:\n",
        "            return 0.,0.\n",
        "        gt_clas = clas[gt_idx]\n",
        "        pos = gt_overlap > 0.4\n",
        "        pos_idx = torch.nonzero(pos)[:,0]\n",
        "        gt_clas[1-pos] = 0 #data.c - 1 # CHANGE\n",
        "        gt_bbox = bbox[gt_idx]\n",
        "        loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
        "        clas_loss  = self._loss_f(b_c, gt_clas)\n",
        "        return loc_loss, clas_loss\n",
        "    \n",
        "    def _ssd_loss(self, pred, targ1, targ2, print_it=False):\n",
        "        lcs,lls = 0.,0.\n",
        "        for b_c,b_bb,bbox,clas in zip(*pred, targ1, targ2):\n",
        "            loc_loss,clas_loss = self._ssd_1_loss(b_c,b_bb,bbox.cuda(),clas.cuda(),print_it)\n",
        "            lls += loc_loss\n",
        "            lcs += clas_loss\n",
        "        if print_it: print(f'loc: {lls}, clas: {lcs}') #CHANGE\n",
        "        return lls+lcs\n",
        "    \n",
        "    def _intersect(self,box_a, box_b):\n",
        "        max_xy = torch.min(box_a[:, None, 2:], box_b[None, :, 2:])\n",
        "        min_xy = torch.max(box_a[:, None, :2], box_b[None, :, :2])\n",
        "        inter = torch.clamp((max_xy - min_xy), min=0)\n",
        "        return inter[:, :, 0] * inter[:, :, 1]\n",
        "\n",
        "    def _box_sz(self, b): \n",
        "        return ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))\n",
        "\n",
        "    def _jaccard(self, box_a, box_b):\n",
        "        inter = self._intersect(box_a, box_b)\n",
        "        union = self._box_sz(box_a).unsqueeze(1) + self._box_sz(box_b).unsqueeze(0) - inter\n",
        "        return inter / union\n",
        "    \n",
        "    def _normalize_bbox(self, bbox): \n",
        "        return (bbox+1.)/2.\n",
        "\n",
        "    \n",
        "    \n",
        "    def save(self, name_or_path):\n",
        "        if '\\\\' in name_or_path or '/' in name_or_path:\n",
        "            path = Path(name_or_path)\n",
        "            name = path.stem\n",
        "            # to make fastai save to both path and with name\n",
        "            temp = self.learn.path\n",
        "            self.learn.path = path.parent\n",
        "            self.learn.model_dir = ''\n",
        "            if not os.path.exists(self.learn.path):\n",
        "                os.makedirs(self.learn.path)            \n",
        "            saved_path = self.learn.save(name, return_path=True)\n",
        "            # undoing changes to self.learn.path and self.learn.model\n",
        "            self.learn.path = temp\n",
        "            self.learn.model_dir = 'models'\n",
        "        else:\n",
        "            temp = self.learn.path\n",
        "            # fixing fastai bug\n",
        "            self.learn.path = self.learn.path.parent\n",
        "            if not os.path.exists(self.learn.path / self.learn.model_dir):\n",
        "                os.makedirs(self.learn.path / self.learn.model_dir)            \n",
        "            saved_path = self.learn.save(name_or_path,  return_path=True)\n",
        "            # undoing changes to self.learn.path\n",
        "            self.learn.path = temp\n",
        "\n",
        "    def load(self, name_or_path):\n",
        "        if '\\\\' in name_or_path or '/' in name_or_path:\n",
        "            path = Path(name_or_path)\n",
        "            name = path.stem\n",
        "            # to make fastai from both path and with name\n",
        "            temp = self.learn.path\n",
        "            self.learn.path = path.parent\n",
        "            self.learn.model_dir = ''\n",
        "            self.learn.load(name)\n",
        "            # undoing changes to self.learn.path and self.learn.model_dir\n",
        "            self.learn.path = temp\n",
        "            self.learn.model_dir = 'models'\n",
        "        else:\n",
        "            temp = self.learn.path\n",
        "            # fixing fastai bug\n",
        "            self.learn.path = self.learn.path.parent            \n",
        "            self.learn.load(name_or_path)\n",
        "            # undoing changes to self.learn.path\n",
        "            self.learn.path = temp\n",
        "        \n",
        "    def show_results(self, rows=5, thresh=0.5, nms_overlap=0.1):\n",
        "        self.learn.show_results(rows=rows, thresh=thresh, nms_overlap=nms_overlap, ssd=self)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1a7hlvFib3E",
        "colab_type": "text"
      },
      "source": [
        "###Crater Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xByQ1jKieap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbox_filenames = [filename for filename in os.listdir('images') if filename.endswith('.txt') and filename != 'classes.txt']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7uLK3tyih5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bbox_filenames = [filename for filename in os.listdir('images') if filename.endswith('.txt') and filename != 'classes.txt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDlguGsyinX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_category(num):\n",
        "  if num == '0':\n",
        "    return 'Crater'\n",
        "  if num == '2':\n",
        "    return 'Dark Dune'\n",
        "  if num == '15':\n",
        "    return 'Slope Streak'\n",
        "  if num == '4':\n",
        "    return 'Bright Dune'\n",
        "  if num == '5':\n",
        "    return 'Impact Ejecta'\n",
        "  if num == '7':\n",
        "    return 'Spider'\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsMod0Zeipzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_voc_bbox(bb, w, h): \n",
        "  voc = []\n",
        "  bbox_width = float(bb[2]) * w\n",
        "  bbox_height = float(bb[3]) * h\n",
        "  center_x = float(bb[1]) * w\n",
        "  center_y = float(bb[0]) * h\n",
        "  voc.append(center_x - (bbox_width / 2))\n",
        "  voc.append(center_y - (bbox_height / 2))\n",
        "  voc.append(center_x + (bbox_width / 2))\n",
        "  voc.append(center_y + (bbox_height / 2))\n",
        "  return voc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSb-GpYhit6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_img2bbox(bbox_filenames):\n",
        "  img2bbox = {}\n",
        "  for filename in bbox_filenames:\n",
        "    with open('images/' + filename) as f:\n",
        "      img_name = filename.split('.')[0] + '.jpg'\n",
        "      img2bbox[img_name] = [[], []]\n",
        "      \n",
        "      lines = f.readlines()\n",
        "      for line in lines:\n",
        "        line_input = line.strip().split(' ')\n",
        "        bbox = get_voc_bbox(list(map(float, line_input[1:])), w=227, h=227)\n",
        "        category = get_category(line_input[0])\n",
        "        img2bbox[img_name][0].append(bbox)\n",
        "        img2bbox[img_name][1].append(category)\n",
        "  return img2bbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqljvrMPiwDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img2bbox = get_img2bbox(bbox_filenames_train)\n",
        "img2bbox_v = get_img2bbox(bbox_filenames_valid)\n",
        "def get_y_func(x):\n",
        "    if x.name in img2bbox:\n",
        "        bboxes, classes = img2bbox[x.name]\n",
        "    else:\n",
        "        bboxes, classes = img2bbox_v[x.name]\n",
        "    return [bboxes, classes] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-oalWA0i0cF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking the bbox\n",
        "bbox = img2bbox['ESP_011289_1950_RED-0146-fv.jpg'][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DJ0eZ1YjcxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from fastai.vision.transform import get_transforms\n",
        "from fastai.vision.data import ObjectItemList, imagenet_stats#, bb_pad_collate\n",
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "\n",
        "PATH = Path(r'images/')\n",
        "\n",
        "data = (SSDObjectItemList.from_folder(PATH)\n",
        "        .split_by_files(list(img2bbox_v.keys()))                          \n",
        "        .label_from_func(get_y_func)\n",
        "        .transform(get_transforms(), tfm_y=True, size=224)\n",
        "        .databunch(bs=64, collate_fn=bb_pad_collate)\n",
        "        .normalize(imagenet_stats))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxfHwUSpjrEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#printing images with GT boxes dataset\n",
        "%%time\n",
        "data.show_batch()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ96UrSLj6hN",
        "colab_type": "text"
      },
      "source": [
        "###Simple SSD(High Accuracy with Focal Loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIGFcznykCDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simple_ssd = SingleShotDetector(data, grids=[4], zooms=[1.0], ratios=[[1.0, 1.0]], focal_loss=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7Ilx7hhkbBq",
        "colab_type": "text"
      },
      "source": [
        "###Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pS4D5CqkUVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simple_ssd.lr_find()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i13bH-CUkKS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training the model\n",
        "simple_ssd.fit(30, lr=slice(1e-3, 1e-2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciT43qxIkyXd",
        "colab_type": "text"
      },
      "source": [
        "####Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpSTWCpikn0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simple_ssd.learn.model.load_state_dict(torch.load('simple_ssd.pth'))\n",
        "simple_ssd.learn.model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "durIBWFKk5Rg",
        "colab_type": "text"
      },
      "source": [
        "####Show Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndWuD1UPk4NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simple_ssd.show_results(rows=16, thresh=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY0BymI7lqpp",
        "colab_type": "text"
      },
      "source": [
        "###Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELTeo4xFlvw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(simple_ssd.learn.model.state_dict(), 'simple_ssd.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHb7Dq_dl1z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simple_ssd.learn.model.load_state_dict(torch.load('simple_ssd.pth'))\n",
        "simple_ssd.learn.model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuWOyxNvl_xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}